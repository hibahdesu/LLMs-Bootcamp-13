{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vcR5u_wa0YXm4HoXDmnJcMVQyA6rl8Ex","timestamp":1690961435666}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Q24hSxA4tA6n"},"source":["# Text classification: Understanding the Customer's Feedback\n","\n","---\n","\n","Text classification is one of the important tasks of text mining\n","\n","![alt text](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1535125878/NLTK3_zwbdgg.png)\n","\n","In this notebook, we will perform Sentiment Analysis on IMDB movies reviews. Sentiment Analysis is the art of extracting people's opinion from digital text. We will use a regression model from Scikit-Learn able to predict the sentiment given a movie review.\n","\n","We will use [the IMDB movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/), which consists of 50,000 movies review (50% are positive, 50% are negative)."]},{"cell_type":"markdown","metadata":{"id":"0O1jA8byt4bV"},"source":["The libraries needed in this exercise are:\n","* [Numpy](http://www.numpy.org/) — a package for scientific computing.\n","* [Pandas](https://pandas.pydata.org/) — a library providing high-performance, easy-to-use data structures and data analysis tools for the Python\n","* [Matplotlib](https://matplotlib.org/) — a package for plotting & visualizations.\n","* [scikit-learn](http://scikit-learn.org/stable/index.html) — a tool for data mining and data analysis.\n","* [NLTK](http://www.nltk.org/) — a platform to work with natural language."]},{"cell_type":"markdown","metadata":{"id":"844CS6rf57X7"},"source":["##Loading the data"]},{"cell_type":"markdown","metadata":{"id":"QAt6rj955meo"},"source":["### Importing the libraries and necessary dictionaries"]},{"cell_type":"code","metadata":{"id":"RRN4WqkltlB5"},"source":["import numpy as np\n","import pandas as pd\n","import nltk\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","\n","# download Punkt Sentence Tokenizer\n","nltk.download('punkt')\n","# download stopwords\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7duM74C95rhN"},"source":["### Loading the dataset in our directory"]},{"cell_type":"code","metadata":{"id":"c48UYWDcg3hR"},"source":["# download IMDB dataset\n","!wget \"https://raw.githubusercontent.com/javaidnabi31/Word-Embeddding-Sentiment-Classification/master/movie_data.csv\" -O \"movie_data.csv\"\n","\n","# list files in current directory\n","!ls -lah"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"77spW4xt5y4R"},"source":["###Reading the dataset file and getting info on it\n","**Question 1:** Use pandas to read the csv file and display the first 5 rows"]},{"cell_type":"code","metadata":{"id":"R0A5QhDlteWj"},"source":["# path to IMDB dataseet\n","\n","\n","# read file (dataset) into our program using pandas\n","\n","\n","# display first 5 rows\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t8oHmgm-6qK2"},"source":["Getting info on our dataset"]},{"cell_type":"code","metadata":{"id":"uQVx6AhqhAiB"},"source":["data.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cPbcG_8k54JZ"},"source":["A balanced dataset in sentiment analysis is a dataset which holds an equal amount of positive sentiment data and negative sentiment data, meaning 50% of the data is positive and 50% is negative"]},{"cell_type":"markdown","source":["**Question 2:** Check if dataset is balanced (number of positive sentiment = number of negative sentiment) by plotting the different classes"],"metadata":{"id":"rgvEJ3BSK_7e"}},{"cell_type":"code","metadata":{"id":"q12nMYY5vPhn"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R4uAuueIwKkS"},"source":["## Text cleaning"]},{"cell_type":"code","metadata":{"id":"qCxs0pSovUOa"},"source":["print(data.review[10])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lAvczEBgxUWl"},"source":["**Question 3:** Let's define a function that would clean each movie review (sentence)"]},{"cell_type":"code","metadata":{"id":"eKKIsHqZwRJR"},"source":["import re\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem.porter import PorterStemmer\n","\n","english_stopwords = stopwords.words('english')\n","stemmer = PorterStemmer()\n","\n","# define cleaning function\n","def clean_review(text):\n","\n","\n","\n","\n","\n","\n","  return text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-NIqPBfK67Zc"},"source":["**Question 4 :** Try it out on an instance of the dataset then on the entire dataset."]},{"cell_type":"code","metadata":{"id":"W4Bn3r1wzvwR"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"24Ycze9C6_yb"},"source":["And now clean the entire dataset reviews"]},{"cell_type":"code","metadata":{"id":"6kHxWkPTz5eA"},"source":["# apply to all dataset\n","data['clean_review'] = data['review'].apply(clean_review)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkVqSSzu2Ax8"},"source":["## Split dataset for training and testing\n","We will split our data into two subsets: a 50% subset will be used for training the model for prediction and the remaining 50% will be used for evaluating or testing its performance. The random state ensures reproducibility of the results."]},{"cell_type":"markdown","source":["**Question 5:** Split your data to get x_train, x_test, y_train and y_test."],"metadata":{"id":"HfMQ4DP0LahH"}},{"cell_type":"code","metadata":{"id":"QPHlwVS71brN"},"source":["from sklearn.model_selection import train_test_split\n","\n","X =\n","y =\n","\n","# Split data into 50% training & 50% test\n","# Use a random state of 42 for example to ensure having the same split\n","\n","\n","print(x_train.shape, y_train.shape)\n","print(x_test.shape, y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wz23g0nD2nhN"},"source":["## Feature extraction with Bag of Words\n"]},{"cell_type":"markdown","source":["**Question 6:**  In this section, apply the Bag of Words method to learn the vocabulary of your text and with it transform your training input data."],"metadata":{"id":"FGHs66FILldh"}},{"cell_type":"code","metadata":{"id":"0_B0vrn-2sON"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# define a CountVectorizer (with binary=True and max_features=10000)\n","\n","\n","# learn the vocabulary of all tokens in our training dataset\n","\n","\n","# transform x_train to bag of words\n","x_train_bow = vectorizer.transform(x_train)\n","x_test_bow = vectorizer.transform(x_test)\n","\n","print(x_train_bow.shape, y_train.shape)\n","print(x_test_bow.shape, y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UtLaJfuw4060"},"source":["## Classification\n","\n","**Question 7:** Your data is ready for classification. For this task use [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"]},{"cell_type":"code","metadata":{"id":"9mS51YGO4hfv"},"source":["from sklearn.linear_model import LogisticRegression\n","\n","# define the LogisticRegression classifier\n","\n","\n","# train the classifier on the training data\n","\n","\n","# get the mean accuracy on the training data\n","\n","\n","print('Training Accuracy:', acc_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Csw7GEm76E5"},"source":["**Question 8:**  Evaluating the performance of your model through its accuracy score"]},{"cell_type":"code","metadata":{"id":"sBJnyoqO5NyE"},"source":["# Evaluate model with test data\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yh5927-d6Gq4"},"source":["## Bonus: Let's use the model to predict!\n","To do so, let's create a predict function which takes as argument your model and the bag of words vectorizer together with a review on which it would predict the sentiment. This review should be cleaned with the `clean_review` function we built, transformed by bag of words and then used for prediction with `model.predict()`."]},{"cell_type":"code","metadata":{"id":"u6kxkZ5m55Ii"},"source":["# define predict function\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7VrNunL18l4a"},"source":["And let's try it out on an example"]},{"cell_type":"code","metadata":{"id":"8z6WCl916flD"},"source":["review = 'The movie was great!'\n","predict(model, vectorizer, review)"],"execution_count":null,"outputs":[]}]}