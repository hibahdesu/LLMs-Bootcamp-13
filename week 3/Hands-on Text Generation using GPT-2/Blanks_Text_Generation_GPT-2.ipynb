{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSwHsPLaYwXTWiduw5E58g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Text Generation using GPT-2 Language Model\n","\n","This notebook demonstrates text generation using the GPT-2 (Generative Pre-trained Transformer 2) language model, a state-of-the-art autoregressive language model developed by OpenAI. The notebook showcases how to utilize the 'transformers' library in Python to interact with GPT-2 and generate coherent and contextually relevant text based on a given prompt."],"metadata":{"id":"L9KNg9aZrDml"}},{"cell_type":"markdown","source":["## Importing Libraries\n","We start by importing the necessary libraries, including the 'transformers' library which provides access to pre-trained language models like GPT-2.\n","\n","The pre-trained GPT-2 model and tokenizer are loaded using the 'GPT2LMHeadModel' and 'GPT2Tokenizer' classes from the 'transformers' library. The GPT-2 model is set up for text generation."],"metadata":{"id":"av9r-C32rMPY"}},{"cell_type":"code","source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"],"metadata":{"id":"iLnoKMQ9psvl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define the Text Generation Function\n","\n","A function named 'generate_text_with_gpt2()' is defined, which takes a prompt as input and uses the GPT-2 model to generate text based on the prompt. The function encodes the prompt, generates text using the GPT-2 model, and decodes the output to obtain human-readable text."],"metadata":{"id":"tRQFrOedrtJP"}},{"cell_type":"code","source":["\n","def generate_text_with_gpt2(prompt, max_length=100):\n","    # Load the pre-trained GPT-2 model and tokenizer\n","    model_name =\n","    tokenizer =\n","    model =\n","\n","    # Encode the prompt and generate text using GPT-2\n","    input_ids =\n","    output_ids =\n","    output_text =\n","\n","    return output_text\n"],"metadata":{"id":"UTifQKdBrsos"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test the Function"],"metadata":{"id":"q_TCXsVlr6qo"}},{"cell_type":"markdown","source":["A sample prompt, such as \"Once upon a time,\" is provided to the 'generate_text_with_gpt2()' function, which generates text based on the prompt. The generated text is then displayed as the output."],"metadata":{"id":"25vkXkugr5a4"}},{"cell_type":"code","source":["\n","# Demo\n","prompt = \"Once upon a time\"\n","generated_text = generate_text_with_gpt2(prompt)\n","\n","print(\"Prompt:\")\n","print(prompt)\n","print(\"\\nGenerated Text:\")\n","print(generated_text)\n"],"metadata":{"id":"Kwm3J0HWr1al"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the case of GPT-2, the model generates text by predicting the next token given the preceding tokens. While GPT-2 is a powerful language model, it is not explicitly trained to avoid generating repeated phrases or sentences. As a result, the model can sometimes get stuck in loops and generate repetitive patterns."],"metadata":{"id":"WKWH_UXbqaQS"}}]}